library(data.table)
library(readr)
library(microbenchmark)
library(ggplot2)
options(scipen=999)
#get folders
folders <- list.files(path = "../Data/all-domestic-certificates", pattern = NULL, all.files = FALSE,
full.names = FALSE, recursive = FALSE,
ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)
folders <- folders[-342] #remove the .txt
regional_LUT <- fread("../Data/folders_geography_LUT.csv")
setkey(regional_LUT, "Folder")
start.time <- Sys.time()
ubdc_LUT <- fread("../Data/ubdc_link.csv",
select = c("lmk_key","ubdc_uprn"),
colClasses = c("lmk_key" = "character",
"ubdc_uprn" = "character"))
setkey(ubdc_LUT,lmk_key)
print(paste('fread:', Sys.time() - start.time)) #aprox 7 mins
checks <- c("INSPECTION_DATE","CURRENT_ENERGY_RATING","CURRENT_ENERGY_EFFICIENCY","LMK_KEY","ubdc_UPRN")
crosssectionalEPCs_byRGN <- list()
longitudinalEPCs_long <- list()
#counter:
#print_counter = 0
LA= folders[2]
start.time <- Sys.time()
for (LA in folders) {
#if( print_counter %% 20 == 0){print(LA)}
print(LA)
certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
colClasses = c(       #'LMK_KEY' = 'character',
'LODGEMENT_DATETIME' = 'character',
'CURRENT_ENERGY_RATING' = 'character',
'CURRENT_ENERGY_EFFICIENCY' = 'character',
'ADDRESS' = 'character',
'POSTCODE' = 'character',
'UPRN' = 'character',
'UPRN_SOURCE' = 'character',
'LOCAL_AUTHORITY' = 'character',
'LOCAL_AUTHORITY_LABEL' = 'character',
'POSTTOWN' = 'character',
'CONSTITUENCY_LABEL' = 'character',
'TRANSACTION_TYPE' = 'character',
'TENURE' = 'character'))
#setkey(certificates, LMK_KEY) #might not be needed
#Create the Longitudinal Dataset
#-------------------------------------------------------------------------------------------------------------------------------
##LUT dups
tmp <- ubdc_LUT[certificates$LMK_KEY, 'ubdc_uprn']
certificates[,ubdc_UPRN := tmp]
##combined str dups
certificates[,str_concat := paste(ADDRESS, POSTCODE)]
###..make col n_UPRN where this would UPRN, or ubdc_UPRN where its missing
certificates[ , n_UPRN := UPRN]
certificates[ n_UPRN == '',  n_UPRN := ubdc_UPRN]
repeat_str <- duplicated(certificates$str_concat)|duplicated(certificates$str_concat, fromLast = T)
#changed syntax because duplicate() won't work. The version of duplicated (duplicated.integer64() does not implement fromLast AND ignores the args! LOL ðŸ¥²)
## example: duplicated(certificates$n_UPRN, fromLast = T ) [c(6971,14575)] = F, T
repeat_nUPRN <- (duplicated(certificates, by = "n_UPRN")|duplicated(certificates, by = "n_UPRN", fromLast = T)) & !(certificates$n_UPRN == '')
dup_idx <- union(which(repeat_str),which(repeat_nUPRN))
duplicated_certificates <- as.data.table(certificates[dup_idx,])
duplicated_certificates <- duplicated_certificates[order(UPRN,str_concat,ubdc_UPRN, INSPECTION_DATE),]
#View(duplicated_certificates[,..check])# these duplicates seems fine
#duplicated_certificates[ n_UPRN == '10009711048',..check]
#Problem 1: Assigning UPRNs
##CASE 1: idential string address repeats with UPRN value sometimes missing
## example: "domestic-E06000001-Hartlepool":'Mount Oswald Nursing Home, 16 Hutton Avenue TS26 9PN'
dict <- duplicated_certificates[ !is.na(n_UPRN), c('str_concat','n_UPRN','INSPECTION_DATE')]
##CASE 2: idential string address repeats with different UPRN values
## example: "domestic-E06000001-Hartlepool":"Gospel Hall, 32 Town Wall TS24 0JQ"
## resolution is to assume the most recent UPRN to be right one
#potential problem
dict <-  dict[order(-INSPECTION_DATE), c('str_concat','n_UPRN')]
dict <-  dict[!duplicated(str_concat), ]
dict <- setkey(as.data.table(dict), str_concat)
duplicated_certificates  <- duplicated_certificates[,n_UPRN := dict[duplicated_certificates$str_concat, 'n_UPRN']]
duplicated_certificates  <- duplicated_certificates[order(n_UPRN, str_concat, -INSPECTION_DATE),]
duplicated_certificates$n_GRP <-ifelse(is.na(duplicated_certificates$n_UPRN), duplicated_certificates$str_concat, duplicated_certificates$n_UPRN )
#View(duplicated_certificates[, c('n_GRP','str_concat','n_UPRN','INSPECTION_DATE')])
#Output: Append to long list
longitudinalEPCs_long<- rbindlist(list(longitudinalEPCs_long,duplicated_certificates ))
#-------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Dataset (include only most recent obvervations of repeat entries)
#------------------------------------------------------------------------------------------------------------------------------
###Problem 2: Identifing all repeats, except the latest observations to create blacklist
tmp_mapping_blacklist <- as.data.table(duplicated_certificates[which( !duplicated(duplicated_certificates$n_GRP) ),]$LMK_KEY )
tmp_mapping <- certificates[!certificates$LMK_KEY %in% tmp_mapping_blacklist$V1,] #keep those outside the blacklist
## Create a list of places by region:
####NOTE: assumes the regions will be seen in order
r_region <- regional_LUT[LA]$RGN11NM
if(LA == folders[1]){
previous_region <- r_region
mapping <- list()
}
if(r_region == previous_region){
mapping <- rbindlist(list(mapping,tmp_mapping ))
}else if(r_region != previous_region){
crosssectionalEPCs_byRGN[[previous_region]] <- mapping
mapping <- list()
mapping <- rbindlist(list(mapping,tmp_mapping ))
previous_region<- regional_LUT[LA]$RGN11NM
}
#------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Meta-dataset
}
save(crosssectionalEPCs_byRGN, file = "../Data/WIP_crossectionalEPCs_up-to-E09000030-TowerHamlets.RData", compress = T)
save(longitudinalEPCs_long, file = "../Data/WIP_logitudinalEPCs_up-to-E09000030-TowerHamlets.RData", compress = T)
object.size(longitudinalEPCs_long)
memory.size(longitudinalEPCs_long)
a <- 'test'
save(a, file = "../Data/RData/deleteMe.RData", compress = T)
save(a, file = "../Data/RData/deleteMe.RData", compress = T)
save(a, file = "../Data/RData/deleteMe.RData")
mapping <- rbindlist(list(mapping,tmp_mapping ), compress = T)
, compress = T
save(a, file = "../Data/RData/deleteMe.RData", compress = T)
print('cat')
folders <- folders[1:3,]
folders <- folders[1:3]
folders
rm(crosssectionalEPCs_byRGN, longitudinalEPCs_long, mapping)
longitudinalEPCs_long <- list()
#counter:
#print_counter = 0
start.time <- Sys.time()
for (LA in folders) {
#if( print_counter %% 20 == 0){print(LA)}
print(LA)
certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
colClasses = c(       #'LMK_KEY' = 'character',
'LODGEMENT_DATETIME' = 'character',
'CURRENT_ENERGY_RATING' = 'character',
'CURRENT_ENERGY_EFFICIENCY' = 'character',
'ADDRESS' = 'character',
'POSTCODE' = 'character',
'UPRN' = 'character',
'UPRN_SOURCE' = 'character',
'LOCAL_AUTHORITY' = 'character',
'LOCAL_AUTHORITY_LABEL' = 'character',
'POSTTOWN' = 'character',
'CONSTITUENCY_LABEL' = 'character',
'TRANSACTION_TYPE' = 'character',
'TENURE' = 'character'))
r_region <- regional_LUT[LA]$RGN11NM
certificates[,RGN11NM := r_region]
certificates[,LAD11NM := regional_LUT[LA]$LAD11NM]
#Create the Longitudinal Dataset
#-------------------------------------------------------------------------------------------------------------------------------
##LUT dups
tmp <- ubdc_LUT[certificates$LMK_KEY, 'ubdc_uprn']
certificates[,ubdc_UPRN := tmp]
##combined str dups
certificates[,str_concat := paste(ADDRESS, POSTCODE)]
###..make col n_UPRN where this would UPRN, or ubdc_UPRN where its missing
certificates[ , n_UPRN := UPRN]
certificates[ n_UPRN == '',  n_UPRN := ubdc_UPRN]
repeat_str <- duplicated(certificates$str_concat)|duplicated(certificates$str_concat, fromLast = T)
#changed syntax because duplicate() won't work. The version of duplicated (duplicated.integer64() does not implement fromLast AND ignores the args! LOL ðŸ¥²)
## example: duplicated(certificates$n_UPRN, fromLast = T ) [c(6971,14575)] = F, T
repeat_nUPRN <- (duplicated(certificates, by = "n_UPRN")|duplicated(certificates, by = "n_UPRN", fromLast = T)) & !(certificates$n_UPRN == '')
dup_idx <- union(which(repeat_str),which(repeat_nUPRN))
duplicated_certificates <- as.data.table(certificates[dup_idx,])
duplicated_certificates <- duplicated_certificates[order(UPRN,str_concat,ubdc_UPRN, INSPECTION_DATE),]
#View(duplicated_certificates[,..check])# these duplicates seems fine
#duplicated_certificates[ n_UPRN == '10009711048',..check]
#Problem 1: Assigning UPRNs
##CASE 1: idential string address repeats with UPRN value sometimes missing
## example: "domestic-E06000001-Hartlepool":'Mount Oswald Nursing Home, 16 Hutton Avenue TS26 9PN'
dict <- duplicated_certificates[ !is.na(n_UPRN), c('str_concat','n_UPRN','INSPECTION_DATE')]
##CASE 2: idential string address repeats with different UPRN values
## example: "domestic-E06000001-Hartlepool":"Gospel Hall, 32 Town Wall TS24 0JQ"
## resolution is to assume the most recent UPRN to be right one
#potential problem
dict <-  dict[order(-INSPECTION_DATE), c('str_concat','n_UPRN')]
dict <-  dict[!duplicated(str_concat), ]
dict <- setkey(as.data.table(dict), str_concat)
duplicated_certificates  <- duplicated_certificates[,n_UPRN := dict[duplicated_certificates$str_concat, 'n_UPRN']]
duplicated_certificates  <- duplicated_certificates[order(n_UPRN, str_concat, -INSPECTION_DATE),]
duplicated_certificates$n_GRP <-ifelse(is.na(duplicated_certificates$n_UPRN), duplicated_certificates$str_concat, duplicated_certificates$n_UPRN )
#View(duplicated_certificates[, c('n_GRP','str_concat','n_UPRN','INSPECTION_DATE')])
#Output: Append to long list
longitudinalEPCs_long<- rbindlist(list(longitudinalEPCs_long,duplicated_certificates ))
#-------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Dataset (include only most recent obvervations of repeat entries)
#------------------------------------------------------------------------------------------------------------------------------
###Problem 2: Identifing all repeats, except the latest observations to create blacklist
tmp_mapping_blacklist <- as.data.table(duplicated_certificates[which( !duplicated(duplicated_certificates$n_GRP) ),]$LMK_KEY )
tmp_mapping <- certificates[!certificates$LMK_KEY %in% tmp_mapping_blacklist$V1,] #keep those outside the blacklist
## Create a list of places by region:
####NOTE: assumes the regions will be seen in order
if(LA == folders[1]){
previous_region <- r_region
mapping <- list()
}
if(r_region == previous_region){
mapping <- rbindlist(list(mapping,tmp_mapping ))
}else if(r_region != previous_region){
save(mapping, file = paste0("../Data/RData/crossSectional",previous_region,".RData") )
mapping <- list()
mapping <- rbindlist(list(mapping,tmp_mapping ))
previous_region<- regional_LUT[LA]$RGN11NM
save(longitudinalEPCs_long, file = paste0("../Data/RData/longitudinalEPCs",previous_region,".RData") )
longitudinalEPCs_long <- list()
}
#------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Meta-dataset
}
print(paste('loop time:', Sys.time() - start.time))
rm(list())
rm(ls = list())
rm(list= ls())
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(readr)
library(microbenchmark)
library(ggplot2)
options(scipen=999)
#get folders
folders <- list.files(path = "../Data/all-domestic-certificates", pattern = NULL, all.files = FALSE,
full.names = FALSE, recursive = FALSE,
ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)
folders <- folders[-342] #remove the .txt
regional_LUT <- fread("../Data/folders_geography_LUT.csv")
setkey(regional_LUT, "Folder")
start.time <- Sys.time()
ubdc_LUT <- fread("../Data/ubdc_link.csv",
select = c("lmk_key","ubdc_uprn"),
colClasses = c("lmk_key" = "character",
"ubdc_uprn" = "character"))
setkey(ubdc_LUT,lmk_key)
print(paste('fread:', Sys.time() - start.time)) #aprox 7 mins
checks <- c("INSPECTION_DATE","CURRENT_ENERGY_RATING","CURRENT_ENERGY_EFFICIENCY","LMK_KEY","ubdc_UPRN")
longitudinalEPCs_long <- list()
#counter:
#print_counter = 0
start.time <- Sys.time()
for (LA in folders) {
if( print_counter %% 20 == 0){print(LA)}
print(LA)
certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
colClasses = c(       #'LMK_KEY' = 'character',
'LODGEMENT_DATETIME' = 'character',
'CURRENT_ENERGY_RATING' = 'character',
'CURRENT_ENERGY_EFFICIENCY' = 'character',
'ADDRESS' = 'character',
'POSTCODE' = 'character',
'UPRN' = 'character',
'UPRN_SOURCE' = 'character',
'LOCAL_AUTHORITY' = 'character',
'LOCAL_AUTHORITY_LABEL' = 'character',
'POSTTOWN' = 'character',
'CONSTITUENCY_LABEL' = 'character',
'TRANSACTION_TYPE' = 'character',
'TENURE' = 'character'))
r_region <- regional_LUT[LA]$RGN11NM
certificates[,RGN11NM := r_region]
certificates[,LAD11NM := regional_LUT[LA]$LAD11NM]
#Create the Longitudinal Dataset
#-------------------------------------------------------------------------------------------------------------------------------
##LUT dups
tmp <- ubdc_LUT[certificates$LMK_KEY, 'ubdc_uprn']
certificates[,ubdc_UPRN := tmp]
##combined str dups
certificates[,str_concat := paste(ADDRESS, POSTCODE)]
###..make col n_UPRN where this would UPRN, or ubdc_UPRN where its missing
certificates[ , n_UPRN := UPRN]
certificates[ n_UPRN == '',  n_UPRN := ubdc_UPRN]
repeat_str <- duplicated(certificates$str_concat)|duplicated(certificates$str_concat, fromLast = T)
#changed syntax because duplicate() won't work. The version of duplicated (duplicated.integer64() does not implement fromLast AND ignores the args! LOL ðŸ¥²)
## example: duplicated(certificates$n_UPRN, fromLast = T ) [c(6971,14575)] = F, T
repeat_nUPRN <- (duplicated(certificates, by = "n_UPRN")|duplicated(certificates, by = "n_UPRN", fromLast = T)) & !(certificates$n_UPRN == '')
dup_idx <- union(which(repeat_str),which(repeat_nUPRN))
duplicated_certificates <- as.data.table(certificates[dup_idx,])
duplicated_certificates <- duplicated_certificates[order(UPRN,str_concat,ubdc_UPRN, INSPECTION_DATE),]
#View(duplicated_certificates[,..check])# these duplicates seems fine
#duplicated_certificates[ n_UPRN == '10009711048',..check]
#Problem 1: Assigning UPRNs
##CASE 1: idential string address repeats with UPRN value sometimes missing
## example: "domestic-E06000001-Hartlepool":'Mount Oswald Nursing Home, 16 Hutton Avenue TS26 9PN'
dict <- duplicated_certificates[ !is.na(n_UPRN), c('str_concat','n_UPRN','INSPECTION_DATE')]
##CASE 2: idential string address repeats with different UPRN values
## example: "domestic-E06000001-Hartlepool":"Gospel Hall, 32 Town Wall TS24 0JQ"
## resolution is to assume the most recent UPRN to be right one
#potential problem
dict <-  dict[order(-INSPECTION_DATE), c('str_concat','n_UPRN')]
dict <-  dict[!duplicated(str_concat), ]
dict <- setkey(as.data.table(dict), str_concat)
duplicated_certificates  <- duplicated_certificates[,n_UPRN := dict[duplicated_certificates$str_concat, 'n_UPRN']]
duplicated_certificates  <- duplicated_certificates[order(n_UPRN, str_concat, -INSPECTION_DATE),]
duplicated_certificates$n_GRP <-ifelse(is.na(duplicated_certificates$n_UPRN), duplicated_certificates$str_concat, duplicated_certificates$n_UPRN )
#View(duplicated_certificates[, c('n_GRP','str_concat','n_UPRN','INSPECTION_DATE')])
#Output: Append to long list
longitudinalEPCs_long<- rbindlist(list(longitudinalEPCs_long,duplicated_certificates ))
#-------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Dataset (include only most recent obvervations of repeat entries)
#------------------------------------------------------------------------------------------------------------------------------
###Problem 2: Identifing all repeats, except the latest observations to create blacklist
tmp_mapping_blacklist <- as.data.table(duplicated_certificates[which( !duplicated(duplicated_certificates$n_GRP) ),]$LMK_KEY )
tmp_mapping <- certificates[!certificates$LMK_KEY %in% tmp_mapping_blacklist$V1,] #keep those outside the blacklist
## Create a list of places by region:
####NOTE: assumes the regions will be seen in order
if(LA == folders[1]){
previous_region <- r_region
mapping <- list()
}
if(r_region == previous_region){
mapping <- rbindlist(list(mapping,tmp_mapping ))
}else if(r_region != previous_region){
save(mapping, file = paste0("../Data/RData/crossSectional_",previous_region,".RData") )
save(longitudinalEPCs_long, file = paste0("../Data/RData/longitudinalEPCs_",previous_region,".RData") )
mapping <- list()
mapping <- rbindlist(list(mapping,tmp_mapping ))
previous_region<- regional_LUT[LA]$RGN11NM
longitudinalEPCs_long <- list()
print(previous_region)
}
#------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Meta-dataset
}
longitudinalEPCs_long <- list()
#counter:
print_counter = 0
start.time <- Sys.time()
for (LA in folders) {
if( print_counter %% 20 == 0){print(LA)}
print(LA)
certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
colClasses = c(       #'LMK_KEY' = 'character',
'LODGEMENT_DATETIME' = 'character',
'CURRENT_ENERGY_RATING' = 'character',
'CURRENT_ENERGY_EFFICIENCY' = 'character',
'ADDRESS' = 'character',
'POSTCODE' = 'character',
'UPRN' = 'character',
'UPRN_SOURCE' = 'character',
'LOCAL_AUTHORITY' = 'character',
'LOCAL_AUTHORITY_LABEL' = 'character',
'POSTTOWN' = 'character',
'CONSTITUENCY_LABEL' = 'character',
'TRANSACTION_TYPE' = 'character',
'TENURE' = 'character'))
r_region <- regional_LUT[LA]$RGN11NM
certificates[,RGN11NM := r_region]
certificates[,LAD11NM := regional_LUT[LA]$LAD11NM]
#Create the Longitudinal Dataset
#-------------------------------------------------------------------------------------------------------------------------------
##LUT dups
tmp <- ubdc_LUT[certificates$LMK_KEY, 'ubdc_uprn']
certificates[,ubdc_UPRN := tmp]
##combined str dups
certificates[,str_concat := paste(ADDRESS, POSTCODE)]
###..make col n_UPRN where this would UPRN, or ubdc_UPRN where its missing
certificates[ , n_UPRN := UPRN]
certificates[ n_UPRN == '',  n_UPRN := ubdc_UPRN]
repeat_str <- duplicated(certificates$str_concat)|duplicated(certificates$str_concat, fromLast = T)
#changed syntax because duplicate() won't work. The version of duplicated (duplicated.integer64() does not implement fromLast AND ignores the args! LOL ðŸ¥²)
## example: duplicated(certificates$n_UPRN, fromLast = T ) [c(6971,14575)] = F, T
repeat_nUPRN <- (duplicated(certificates, by = "n_UPRN")|duplicated(certificates, by = "n_UPRN", fromLast = T)) & !(certificates$n_UPRN == '')
dup_idx <- union(which(repeat_str),which(repeat_nUPRN))
duplicated_certificates <- as.data.table(certificates[dup_idx,])
duplicated_certificates <- duplicated_certificates[order(UPRN,str_concat,ubdc_UPRN, INSPECTION_DATE),]
#View(duplicated_certificates[,..check])# these duplicates seems fine
#duplicated_certificates[ n_UPRN == '10009711048',..check]
#Problem 1: Assigning UPRNs
##CASE 1: idential string address repeats with UPRN value sometimes missing
## example: "domestic-E06000001-Hartlepool":'Mount Oswald Nursing Home, 16 Hutton Avenue TS26 9PN'
dict <- duplicated_certificates[ !is.na(n_UPRN), c('str_concat','n_UPRN','INSPECTION_DATE')]
##CASE 2: idential string address repeats with different UPRN values
## example: "domestic-E06000001-Hartlepool":"Gospel Hall, 32 Town Wall TS24 0JQ"
## resolution is to assume the most recent UPRN to be right one
#potential problem
dict <-  dict[order(-INSPECTION_DATE), c('str_concat','n_UPRN')]
dict <-  dict[!duplicated(str_concat), ]
dict <- setkey(as.data.table(dict), str_concat)
duplicated_certificates  <- duplicated_certificates[,n_UPRN := dict[duplicated_certificates$str_concat, 'n_UPRN']]
duplicated_certificates  <- duplicated_certificates[order(n_UPRN, str_concat, -INSPECTION_DATE),]
duplicated_certificates$n_GRP <-ifelse(is.na(duplicated_certificates$n_UPRN), duplicated_certificates$str_concat, duplicated_certificates$n_UPRN )
#View(duplicated_certificates[, c('n_GRP','str_concat','n_UPRN','INSPECTION_DATE')])
#Output: Append to long list
longitudinalEPCs_long<- rbindlist(list(longitudinalEPCs_long,duplicated_certificates ))
#-------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Dataset (include only most recent obvervations of repeat entries)
#------------------------------------------------------------------------------------------------------------------------------
###Problem 2: Identifing all repeats, except the latest observations to create blacklist
tmp_mapping_blacklist <- as.data.table(duplicated_certificates[which( !duplicated(duplicated_certificates$n_GRP) ),]$LMK_KEY )
tmp_mapping <- certificates[!certificates$LMK_KEY %in% tmp_mapping_blacklist$V1,] #keep those outside the blacklist
## Create a list of places by region:
####NOTE: assumes the regions will be seen in order
if(LA == folders[1]){
previous_region <- r_region
mapping <- list()
}
if(r_region == previous_region){
mapping <- rbindlist(list(mapping,tmp_mapping ))
}else if(r_region != previous_region){
save(mapping, file = paste0("../Data/RData/crossSectional_",previous_region,".RData") )
save(longitudinalEPCs_long, file = paste0("../Data/RData/longitudinalEPCs_",previous_region,".RData") )
mapping <- list()
mapping <- rbindlist(list(mapping,tmp_mapping ))
previous_region<- regional_LUT[LA]$RGN11NM
longitudinalEPCs_long <- list()
print(previous_region)
}
#------------------------------------------------------------------------------------------------------------------------------
#Create the Crossectional Meta-dataset
}
print(paste('loop time:', Sys.time() - start.time))
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
load("../Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
load("../Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
region <- London
region <- 'London'
load("../Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
getwd()
setwd('C:/Users/billi/Dropbox/_PhD/Application Documents/CASA RA/RA OS NARRATE CASA/Code')
region <- 'London'
load("../Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
getwd()
load("./Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
load("C:/Users/billi/Dropbox/_PhD/Application Documents/CASA RA/RA OS NARRATE CASA/Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
region <- 'South East'
load("C:/Users/billi/Dropbox/_PhD/Application Documents/CASA RA/RA OS NARRATE CASA/Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
load("C:/Users/billi/Dropbox/_PhD/Application Documents/CASA RA/RA OS NARRATE CASA/Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
region <- 'South East'
load("C:/Users/billi/Dropbox/_PhD/Application Documents/CASA RA/RA OS NARRATE CASA/Data/RData_longitudinal/longitudinalEPCs_",region,".RData")
load("C:/Users/billi/Dropbox/_PhD/Application Documents/CASA RA/RA OS NARRATE CASA/Data/RData_longitudinal/longitudinalEPCs_South East.RData")
tmp <- longitudinalEPCs_long
start.time <- Sys.time()
tmp <- str_dups_deltas_c11 %>%
group_by(LOCAL_AUTHORITY, combined) %>% #similarity metric here
summarise(appears = n())
long <- longitudinalEPCs_long
tmp <- lng %>%
group_by(LOCAL_AUTHORITY, combined) %>% #similarity metric here
summarise(appears = n())
tmp <- long %>%
group_by(LOCAL_AUTHORITY, combined) %>% #similarity metric here
summarise(appears = n())
tmp <- long %>%
group_by(LAD11NM, combined) %>% #similarity metric here
summarise(appears = n())
tmp <- long %>%
group_by(LAD11NM, n_GRP) %>% #similarity metric here
summarise(appears = n())
View(tmp)
hist(tmp$appears)
appearance_matrix <- tmp %>%
group_by(appears) %>%
summarise(count = n())
View(appearance_matrix)
appearance_matrix <- tmp %>%
group_by(appears) %>%
summarise(count = n()
region = region)
region <- "South East"
appearance_matrix <- tmp %>%
group_by(appears) %>%
summarise(count = n(),
region = region)
View(appearance_matrix)
View(tmp)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
start.time <- Sys.time()
ubdc_link <- read_csv("../Data/ubdc_link.csv",
col_types = cols(record = col_character(),
record1 = col_character()))
View(unique(long$TRANSACTION_TYPE))
knitr::opts_chunk$set(echo = TRUE)
library(readr)
#library(DescTools)
library(dplyr)
library(tidyr)
#get folders
folders <- list.files(path = "../Data/all-domestic-certificates", pattern = NULL, all.files = FALSE,
full.names = FALSE, recursive = FALSE,
ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)
folders <- folders[-342] #remove the .txt
tenure_LUT <- list()
start.time <- Sys.time()
for (LA in folders) {
#print(LA)
certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
select = 'TENURE',
colClasses = c('TENURE' = 'character'))
tenure_LUT[[LA]] <- unique(certificates$TENURE)
}
unique <- as.data.frame(unlist(tenure_LUT))
unique <- unique(unique$`unlist(tenure_LUT)`)
print(paste('loop time:', Sys.time() - start.time))#"loop time: 3.63205520583524"
View(tenure_LUT)
View(unique)
a <- head(tenure_LUT)
unlist(a)
View(unlist(a))
knitr::opts_chunk$set(echo = TRUE)
library("xlsx")
folder_to_factor
View(as.data.frame(head(unlist(tenure_LUT)))
)
knitr::opts_chunk$set(echo = TRUE)
folder_to_factor <- as.data.frame(unlist(tenure_LUT))
tenure_LUT <- unique(folder_to_factor$`unlist(tenure_LUT)`)
knitr::opts_chunk$set(echo = TRUE)
library("xlsx")
write.xlsx2(tenure_LUT, file = "../Data/OS-N_EPC_v10_LUT+dictionaries.xlsx",
sheetName = "tenure", col.names = TRUE, row.names = TRUE, append = FALSE)
colnames(tenure_LUT)
names(tenure_LUT)
