---
title: "Duplicate (strings) EPCs in V10"
author: "Boyana Buyuklieva"
date: "May 20, 2022"
output: html_document
---

#This version is has linear time complexity. 

```{r setup, include=FALSE, echo = T}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(readr)
library(microbenchmark)
library(ggplot2)
options(scipen=999)

#get folders
folders <- list.files(path = "../Data/all-domestic-certificates", pattern = NULL, all.files = FALSE,
           full.names = FALSE, recursive = FALSE,
           ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)
folders <- folders[-342] #remove the .txt


regional_LUT <- fread("../Data/folders_geography_LUT.csv")
setkey(regional_LUT, "Folder")

start.time <- Sys.time()
ubdc_LUT <- fread("../Data/ubdc_link.csv",  
                  select = c("lmk_key","ubdc_uprn"),
                  colClasses = c("lmk_key" = "character",
                                 "ubdc_uprn" = "character"))

setkey(ubdc_LUT,lmk_key)
print(paste('fread:', Sys.time() - start.time)) #aprox 7 mins


checks <- c("INSPECTION_DATE","CURRENT_ENERGY_RATING","CURRENT_ENERGY_EFFICIENCY","LMK_KEY","ubdc_UPRN")

```




# Duplicate Defintion Testing
```{r loop}
mapping_blacklist <- list()
#counter = 0

LA= folders[2]
start.time <- Sys.time()
for (LA in folders) {
  
  #if( counter %% 20 == 0){print(LA)} 
  print(LA)
  certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
                        colClasses = c(       #'LMK_KEY' = 'character', 
                                              'LODGEMENT_DATETIME' = 'character',
                                              'CURRENT_ENERGY_RATING' = 'character',
                                              'CURRENT_ENERGY_EFFICIENCY' = 'character',
                                              'ADDRESS' = 'character',
                                              'POSTCODE' = 'character',
                                              'UPRN' = 'character',
                                              'UPRN_SOURCE' = 'character',
                                              'LOCAL_AUTHORITY' = 'character',
                                              'LOCAL_AUTHORITY_LABEL' = 'character',
                                              'POSTTOWN' = 'character',
                                              'CONSTITUENCY_LABEL' = 'character',
                                              'TRANSACTION_TYPE' = 'character',
                                              'TENURE' = 'character'))
    #setkey(certificates, LMK_KEY) #might not be needed
    

    #Create the Longitudinal Dataset
    ##LUT dups
    tmp <- ubdc_LUT[certificates$LMK_KEY, 'ubdc_uprn']
    certificates[,ubdc_UPRN := tmp]
    
    ##combined str dups
    certificates[,str_concat := paste(ADDRESS, POSTCODE)]

    ###..make col n_UPRN where this would UPRN, or ubdc_UPRN where its missing
    certificates[ , n_UPRN := UPRN] 
    certificates[ n_UPRN == '',  n_UPRN := ubdc_UPRN]
    
    
    repeat_str <- duplicated(certificates$str_concat)|duplicated(certificates$str_concat, fromLast = T)
    
    #changed syntax because duplicate() won't work. The version of duplicated (duplicated.integer64() does not implement fromLast AND ignores the args! LOL ðŸ¥²)
    ## example: duplicated(certificates$n_UPRN, fromLast = T ) [c(6971,14575)] = F, T
    repeat_nUPRN <- (duplicated(certificates, by = "n_UPRN")|duplicated(certificates, by = "n_UPRN", fromLast = T)) & !(certificates$n_UPRN == '')
 

    dup_idx <- union(which(repeat_str),which(repeat_nUPRN))
    duplicated_certificates <- as.data.table(certificates[dup_idx,])
    duplicated_certificates <- duplicated_certificates[order(UPRN,str_concat,ubdc_UPRN, INSPECTION_DATE),]
    #View(duplicated_certificates[,..check])# these duplicates seems fine
    #duplicated_certificates[ n_UPRN == '10009711048',..check]
    
    
    
    #Problem 1: Assigning UPRNs
    ##CASE 1: idential string address repeats with UPRN value sometimes missing
    ## example: "domestic-E06000001-Hartlepool":'Mount Oswald Nursing Home, 16 Hutton Avenue TS26 9PN'
    dict <- duplicated_certificates[ !is.na(n_UPRN), c('str_concat','n_UPRN','INSPECTION_DATE')]
    
    ##CASE 2: idential string address repeats with different UPRN values
    ## example: "domestic-E06000001-Hartlepool":"Gospel Hall, 32 Town Wall TS24 0JQ"
    ## resolution is to assume the most recent UPRN to be right one
    #potential problem
    dict <-  dict[order(-INSPECTION_DATE), c('str_concat','n_UPRN')]
    dict <-  dict[!duplicated(str_concat), ]
    dict <- setkey(as.data.table(dict), str_concat)
    duplicated_certificates  <- duplicated_certificates[,n_UPRN := dict[duplicated_certificates$str_concat, 'n_UPRN']] 
    duplicated_certificates  <- duplicated_certificates[order(n_UPRN, str_concat, -INSPECTION_DATE),]
    duplicated_certificates$n_GRP <-ifelse(is.na(duplicated_certificates$n_UPRN), duplicated_certificates$str_concat, duplicated_certificates$n_UPRN )
    #View(duplicated_certificates[, c('n_GRP','str_concat','n_UPRN','INSPECTION_DATE')])
    
    
    #Problem 2: Identifing all repeats, except the latest observations to create blacklist
    tmp_mapping_blacklist <- as.data.table(duplicated_certificates[which( !duplicated(duplicated_certificates$n_GRP) ),]$LMK_KEY )
    
    mapping_blacklist <- rbindlist(list(mapping_blacklist,tmp_mapping_blacklist ))
}
print(paste('loop time:', Sys.time() - start.time))



test <- list()
region <- regional_LUT[LA]$RGN11NM

test[[]] <- tmp_mapping_blacklist

if(LA = folders[1]){
  
}


#set the regions counter
region <- regional_LUT[folders[1]]$RGN11NM


#if you are still in the same region, write to the same table
if(region == regional_LUT[folders[LA]]$RGN11NM){
  
}else{
    region <- regional_LUT[folders[LA]]$RGN11NM 
  #reset the blacklist
  #resent the duplicate list
  #reset the unique

  }





      
if(F){
      
    which(duplicated_certificates[!is.na(n_UPRN)]$n_UPRN)
    union( which(duplicated(duplicated_certificates$n_UPRN)), which(duplicated(duplicated_certificates$n_UPRN))
    
    
    
    ##check the maximum duplication of 'str_concat'
    
    
    #issue:
    testcase <- certificates[n_UPRN == '10009711003', c('str_concat','n_UPRN')]
    testcase$n_UPRN[1] == testcase$n_UPRN[2]
    duplicated(testcase$n_UPRN)|duplicated(testcase$n_UPRN, fromLast = T) 
    
    
    certificates[n_UPRN == '10009711003', c('str_concat','n_UPRN')]
    duplicated_certificates[n_UPRN == '10009711003', c('str_concat','n_UPRN')]
    
    
    
    
  
    
    
    
    #create new columns for the RGN & LAD
    r_LAD <- regional_LUT[LA]$LAD11NM
    r_region <- regional_LUT[LA]$RGN11NM
    r_UPRNmismatch <- sum(which(certificates[, ubdc_UPRN != UPRN ]))
    
    certificates[,RGN11NM := r_region]
    certificates[,LAD11NM := r_LAD]
    
    #Create the metadata
    row<- data.table(r_LAD,
                     N = lengths(certificates)[1],
                     naUPRN = sum(is.na(certificates$UPRN)),
                     diffUPRN_LUTpriority = #both !is.na(), but different values 
                     r_region, LA )
    
    
    
    
   
    
    
      
  #Add the dups counts at folder level
  row <- cbind(row,length(certificates$LMK_KEY) )#denominator
  #Count empty UPRNs 
  row <- cbind(row,sum(is.na(certificates$UPRN)))  
  
    
  if(F){
  ###Dups df #######################################
  ##Baseline: by string match
  certificates$combined <- paste0(certificates$ADDRESS, certificates$POSTCODE) #measure of repeat entry here
  tmpdups <- certificates[duplicated(certificates$combined) | duplicated(certificates$combined, fromLast = TRUE),]
  tmpdups <- tmpdups[order(tmpdups$combined, tmpdups$INSPECTION_DATE),]
  str_dups <- rbind(str_dups,tmpdups)
  row <- cbind(row, length(tmpdups$LMK_KEY)) 
  
  
  #Based on UPRNs
  tmpdups1 <- certificates[duplicated(certificates$UPRN) | duplicated(certificates$UPRN, fromLast = TRUE),]
  uprn_dups <- rbind(uprn_dups,tmpdups1)
  

  row <- cbind(row, length(tmpdups1$LMK_KEY) ) 
    }
    
  #DIRECTIONS TO EXPLORE
  #certificates$udbc_UPRN <- ubdc_link$ubdc_uprn[bsearch(certificates$LMK_KEY, ubdc_link$lmk_key)]
  #binsearch / gtools
  #make ubdc_link$ubdc_uprn  a data.table , then setkey(data.table, key)  // touch by data.table[key]
  #test!
  #library(Dict)
  #ages <- Dict$new(ubdc_link$lmk_key,ubdc_link$ubdc_uprn)
  #Manual Based on V9 LUT:
  #start.time <- Sys.time()
  
  
  certificates$udbc_UPRN <- ubdc_link$ubdc_uprn[match(certificates$LMK_KEY, ubdc_link$lmk_key)]
  tmpdups2_2 <- certificates[duplicated(certificates$udbc_UPRN) | duplicated(certificates$udbc_UPRN, fromLast = TRUE),]
  udbc_UPRN <- rbind(udbc_UPRN,tmpdups2_2)
  #print(paste('time without unlist:', Sys.time() - start.time)) #"time without unlist: 3.05"
  row <- cbind(row, length(tmpdups2_2$LMK_KEY)) 
  
  folders_meta_dups <-rbind(folders_meta_dups, row)
  
  rm(tmpdups2_2,row)
  #rm(tmpdups,tmpdups1,tmpdups2_2,row)
  #gc()
  
  counter = counter + 1
}
#summary: UPRNS alone took 2h15 mins to complete. Creating dupsdf of 3.9GB 
#summary: UPRNS alone took 3h+  to complete. Creating dupsdf of 3.9GB 
#names(folders_meta_dups) <- c('folder', 'totalRows', 'NA_uprn', 'ubdc_link_uniq')
#write.csv(folders_meta_dups, '../Outputs/folders_meta_dups_ubdc_link_uniq.csv')
#save(udbc_UPRN, file = '../Data/WIP_udbc_UPRN.RData')

names(folders_meta_dups) <- c('folder', 'totalRows', 'NA_uprn','str_uniq', 'uprn_uniq', 'udbcUPRN_uniq')
}

```





# Feature Engineering Set-Up

```{r heavyload, cache=TRUE}
start.time <- Sys.time()


#loads str_dups [7 847 301]
load(file = './MetaData&StringDups.RData')

#Df of all rows that repeat
tmp <- str_dups[,subsetCols ]
rm(str_dups)

##memory.size()
gc()#collect garbage 


#order by similarity & date
dupcol <- 'combined'
date <- 'INSPECTION_DATE'

tmp <- tmp[order(tmp[,dupcol],tmp[,date]),]
#create a faster key, based on the order
tmp$n_IDx <- seq(1,length(tmp$LMK_KEY),1)


print(paste('time to load:', Sys.time() - start.time))#9 mins
```

```{r define_engineered-features, cache=TRUE}
start.time <- Sys.time()


#flag first entries   
tmp$n_firstEntry <- F
firstEntry <-which(!duplicated(tmp$combined)) #3539058
tmp$n_firstEntry[firstEntry] <- T 
rm(firstEntry)

#set up the time column, relative to Inspection Date
tmp$n_deltaDays <-  0

#Delta(ER)
#might cause problems without trimming white spaces and caps
tmp$n_dER <- as.numeric(factor(tmp$CURRENT_ENERGY_RATING, 
                       ordered = T, levels = c('A','B','C','D','E','F','G')))
tmp$n_dEE <- tmp$CURRENT_ENERGY_EFFICIENCY


print(paste('runtime:', Sys.time() - start.time))#2 mins
```








#Simplified Version of Deltas

```{r solved_faster}

testingN <- length(tmp$combined)
# testingN <- 50000

start.time <- Sys.time()
tester <- head(tmp,testingN)


#vector giving  start of the repeats / group 
rangeStarts <- numeric(testingN)
for (row in tester$n_IDx) {
  
  if (tester$n_firstEntry[row] == T) {
    groupStart <- row
  }
  
  rangeStarts[row] <- groupStart
} 
print(paste('loop runtime:', Sys.time() - start.time)) # (.2 sec / 5k)  (20s / 8M)



start.time <- Sys.time()
tester$n_dER <- tester$n_dER[rangeStarts] - tester$n_dER # factor as numbers
tester$n_dEE <- tester$n_dEE - tester$n_dEE[rangeStarts]
tester$n_deltaDays <- as.numeric(difftime(tester$INSPECTION_DATE, tester$INSPECTION_DATE[rangeStarts], units = c("days"))) 
print(paste('operation runtime:', Sys.time() - start.time)) # (0.01 sec / 5k) (.5 / 8M)


print(paste('runtime:', Sys.time() - start.time)) # (approx 60s / 8 m)

#View(tester[,checks])

```



