---
title: "Checkers_Scratchpad"
author: "Boyana Buyuklieva"
date: "August 9, 2022"
output: html_document
---

```{r}
cleanup <- list.files("C:\\Users\\bonni\\Dropbox\\_PhD\\Application Documents\\CASA RA\\RA OS NARRATE CASA\\Code" )

write.csv(cleanup, "C:\\Users\\bonni\\Dropbox\\_PhD\\Application Documents\\CASA RA\\RA OS NARRATE CASA\\Code\\ReadMe.csv")
```


##title: "CS_P3"


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache.lazy = FALSE)
# library(dplyr)
# library(tidyverse)
# library(data.table)
# library(readr)
# library(foreign)
# library(ggExtra)
# library(gridExtra)


# loads: loadRData
source("../Outputs/Thesis_custom_scripts.R", local = knitr::knit_global())
#big_SC_dt<- loadRData( paste0("../Data/RData_crossSectional/big_crossSect_EPCs_cleaned_N16m984358.RData") )
#save(additional_dt, file = paste0("../Data/RData_crossSectional/big_crossSect_EPCs_cleaned_N16m984358_additional_dt.RData") )



#formatting:
lettermapping <-  data.frame( letter = c('A','B','C','D','E','F','G'), 
                              cutoff = c(92, 81, 69, 55, 39, 21, 0))

EDA_cols <- read_csv("../Data/EDA_colour_scheme.csv")
#EDA_cols <- subset(EDA_cols[EDA_cols$geography_name %in%  cross_data, ])

###IMD:LOAD DATA
#multiple deprivation EW
IMD19<- read.dbf("../Data/_shapefiles/Lower_Super_Output_Area_(LSOA)_IMD_2019__(OSGB1936)/Lower_Super_Output_Area_(LSOA)_IMD_2019__(OSGB1936).dbf")

#income deprivation E
income_imd2019lsoa_E <- fread("../Data/imd2019lsoa/imd2019lsoa.csv",
                     drop="Units", #empty column anyway
                     colClasses = c( "FeatureCode" = "character",
                                     "Measurement" = "character",
                                     "Value" = "numeric",
                                     "Indices of Deprivation" = "character"))
#Measurements are: "Rank"   "Decile" "Score"
#income_imd2019lsoa_E <- setNames(income_imd2019lsoa_E, c("lsoa11cd","Date","Measurement","Value","Indices of Deprivation") )
setnames(income_imd2019lsoa_E, c("FeatureCode"), c("lsoa11cd"))



#get loopUp
LUT_tenure <- read_excel("../Data/OS-N_EPC_v10_LUT+dictionaries.xlsx", sheet = "TENURE",range = cell_cols("B:C"))
LUT_builtForm <- read_excel("../Data/OS-N_EPC_v10_LUT+dictionaries.xlsx", sheet = "BUILT_FORM",range = cell_cols("B:C"))
#LUT_age_band <- entries_to_factors(column_to_extract_factors_from = "CONSTRUCTION_AGE_BAND")
#LUT_transaction <- entries_to_factors(column_to_extract_factors_from = "TRANSACTION_TYPE")
```








```{r UPRN_match_colums}
#CREATE NEW COLUMNS
#N1: info on UPRNs differences and NAs
big_Dt_CSsubset_N6M7[, n_erNoUPRN := ifelse(UPRN == ubdc_UPRN,'same','diffUPRNs')]
big_Dt_CSsubset_N6M7[, n_erNoUPRN := ifelse(UPRN == "" | is.na(UPRN),'diffUPRNs_NA_UPRN',n_erNoUPRN) ]
big_Dt_CSsubset_N6M7[, n_erNoUPRN := ifelse(ubdc_UPRN == ""| is.na(ubdc_UPRN),'diffUPRNs_NA_ubdc_UPRN',n_erNoUPRN) ]
big_Dt_CSsubset_N6M7[, n_erNoUPRN := ifelse(n_UPRN == "" | is.na(n_UPRN),'noUPRN',n_erNoUPRN) ]
```

```{r misc_Crel & rooms}
#N2: create C relative column
big_Dt_CSsubset_N6M7[, n_Crel:= ifelse(CURRENT_ENERGY_RATING == 'C', 'C', 
                                       ifelse(CURRENT_ENERGY_RATING %in% c('A', 'B'), 'C+', 
                                              ifelse(CURRENT_ENERGY_RATING %in% c('D', 'E','F','G'),'C-','NA' )))]
#big_Dt_CSsubset_N6M7[CURRENT_ENERGY_RATING =="INVALID!", ]$CURRENT_ENERGY_EFFICIENCY
big_Dt_CSsubset_N6M7[n_Crel =="NA", n_Crel:= ifelse(CURRENT_ENERGY_EFFICIENCY > 100, 'C+', 'C-')]
  


#Formatting n_Crel:
fctr_levels <- c("C+","C","C-")
big_Dt_CSsubset_N6M7[,n_Crel := factor(n_Crel, levels = fctr_levels, ordered = T)]
#Formatting NUMBER_HABITABLE_ROOMS:
#tally <- big_Dt_CSsubset_N6M7[, .(n = .N) ,by=NUMBER_HABITABLE_ROOMS ]
big_Dt_CSsubset_N6M7[, NUMBER_HABITABLE_ROOMS:=as.integer(NUMBER_HABITABLE_ROOMS)]
```



```{r attach_IMDs}
##ATTACH DATA 
big_Dt_CSsubset_N6M7[IMD19,  on = 'lsoa11cd', c('n_IMDRank','n_IMDDecil') := .(IMDRank,IMDDecil)]

#Add IoD
##can select other IoD here
#b.income
imd_bincome <-  income_imd2019lsoa_E[ `Indices of Deprivation` == "b. Income Deprivation Domain",]
imd_bincome <-dcast(imd_bincome, lsoa11cd ~ Measurement, value.var = c("Value"))
big_Dt_CSsubset_N6M7[imd_bincome,  on = 'lsoa11cd', c('n_bIoDRank_income','n_bIoDDecil_income') := .(Rank,Decile)]
#g.barriers
imd_gbarriers <-  income_imd2019lsoa_E[ `Indices of Deprivation` == "g. Barriers to Housing and Services Domain",]
imd_gbarriers <-dcast(imd_gbarriers, lsoa11cd ~ Measurement, value.var = c("Value"))
big_Dt_CSsubset_N6M7[imd_gbarriers,  on = 'lsoa11cd', c('n_gIoDRank_barriers','n_gIoDDecil_barriers') := .(Rank,Decile)]
```
 
```{r extreme_values_treatment}
#Edit 1: CEE values over 100 are set to 101
#round(quantile(big_Dt_CSsubset_N6M7$CURRENT_ENERGY_EFFICIENCY, 0.99, na.rm = T),0) # 87
big_Dt_CSsubset_N6M7[, n_CURRENT_ENERGY_EFFICIENCY := ifelse( CURRENT_ENERGY_EFFICIENCY>100 ,101, CURRENT_ENERGY_EFFICIENCY)]
# round(quantile(big_Dt_CSsubset_N6M7$POTENTIAL_ENERGY_EFFICIENCY, 0.99, na.rm = T),0) # 97
big_Dt_CSsubset_N6M7[, n_POTENTIAL_ENERGY_EFFICIENCY := ifelse( POTENTIAL_ENERGY_EFFICIENCY>100 ,101, POTENTIAL_ENERGY_EFFICIENCY)]

#Edit 2: EIC values over 100 are set to 101
# round(quantile(big_Dt_CSsubset_N6M7$ENVIRONMENT_IMPACT_CURRENT, 0.99, na.rm = T),0) # 92
big_Dt_CSsubset_N6M7[, n_ENVIRONMENT_IMPACT_CURRENT := ifelse( ENVIRONMENT_IMPACT_CURRENT>100 ,101, ENVIRONMENT_IMPACT_CURRENT)]
#round(quantile(big_Dt_CSsubset_N6M7$ENVIRONMENT_IMPACT_POTENTIAL, 0.99, na.rm = T),0) # 99
big_Dt_CSsubset_N6M7[, n_ENVIRONMENT_IMPACT_POTENTIAL := ifelse( ENVIRONMENT_IMPACT_POTENTIAL>100 ,101, ENVIRONMENT_IMPACT_POTENTIAL)]

#Edit 3: Places with over 7 habitable rooms are grouped together into 7+
#round(quantile(big_Dt_CSsubset_N6M7$NUMBER_HABITABLE_ROOMS, 0.99, na.rm = T),0) # is 10
fctr_levels <- c(paste0(seq(1,9,1), 'HaR'), '+10HaR' )
big_Dt_CSsubset_N6M7[ , n_habitable_rooms_grp := ifelse( NUMBER_HABITABLE_ROOMS>9,'+10HaR', paste0(NUMBER_HABITABLE_ROOMS,'HaR'))]
big_Dt_CSsubset_N6M7[ , n_habitable_rooms_grp := factor(n_habitable_rooms_grp, levels = fctr_levels, ordered = T)]

#Edit 4: Places with over 9 heated rooms are grouped together into 8+
#round(quantile(big_Dt_CSsubset_N6M7$NUMBER_HEATED_ROOMS, 0.99, na.rm = T),0) # is 9
fctr_levels <- c(paste0(seq(1,8,1), 'HtR'), '+9HtR' )
big_Dt_CSsubset_N6M7[ , n_heated_rooms_grp := ifelse( NUMBER_HEATED_ROOMS>8,'+9HtR', paste0(NUMBER_HEATED_ROOMS,'HtR'))]
big_Dt_CSsubset_N6M7[ , n_heated_rooms_grp := factor(n_heated_rooms_grp, levels = fctr_levels, ordered = T)]

#Edit 5: Floor Area. 
#Note min bedroom size is 6.5m2 = 7m2
#Max is 270, based on the 99 percentile of the entries
maxthreshold <- round(quantile(big_Dt_CSsubset_N6M7$TOTAL_FLOOR_AREA, 0.99, na.rm = T),0) # 270
#min: round(quantile(big_Dt_CSsubset_N6M7$TOTAL_FLOOR_AREA, 0.01, na.rm = T),0), 27m2 
print(paste('The 99 percentile of floor area is: ', maxthreshold, 'm2'))
big_Dt_CSsubset_N6M7[, n_TOTAL_FLOOR_AREA  := ifelse( TOTAL_FLOOR_AREA < 6 ,6, TOTAL_FLOOR_AREA)]
big_Dt_CSsubset_N6M7[, n_TOTAL_FLOOR_AREA  := ifelse( n_TOTAL_FLOOR_AREA > maxthreshold , maxthreshold+1, n_TOTAL_FLOOR_AREA)]


#Edit 6: Make Income deprivation groups (b.)
big_Dt_CSsubset_N6M7[ , n_bIoDDecil_income_grp := cut(n_bIoDDecil_income,
                            breaks = c(0, 3, 7, Inf),
                            include.lowest= TRUE, labels=c('IncomeDeprived_1-3','AverageIncome_4-7','IncomeUnDeprived_8-10'))]

#Edit 6: Make barriers deprivation groups (g.)
big_Dt_CSsubset_N6M7[ , n_gIoDDecil_housing_grp := cut(n_gIoDDecil_barriers,
                            breaks = c(0, 3, 7, Inf),
                            include.lowest= TRUE, labels=c('H&S_Deprived_1-3','AverageAccess_4-7','H&S_UnDeprived_8-10'))]



#Edit 8: Difference in CEE & CEI
big_Dt_CSsubset_N6M7[ , nn_CEE_rating := cut(CURRENT_ENERGY_EFFICIENCY,
                            breaks = c(rev(lettermapping$cutoff), Inf),
                            right = F, #includes the lower value
                            labels=  rev(lettermapping$letter)) ]

big_Dt_CSsubset_N6M7[ , nn_CEI_rating := cut(ENVIRONMENT_IMPACT_CURRENT,
                            breaks = c(rev(lettermapping$cutoff), Inf),
                            right = F, #includes the lower value
                            labels=  rev(lettermapping$letter)) ]

big_Dt_CSsubset_N6M7[ , nn_letter_Diff_CEE_EIC := ifelse(nn_CEE_rating == nn_CEI_rating, 'same letter rate', 
                                                         ifelse(CURRENT_ENERGY_EFFICIENCY > ENVIRONMENT_IMPACT_CURRENT, 'Better Running', 'Less C02') ) ]
```


```{r extreme_values_treatment}
#Edited Variable 1: Potential Change PEE 
big_Dt_CSsubset_N6M7[, nn_potEE := n_POTENTIAL_ENERGY_EFFICIENCY - n_CURRENT_ENERGY_EFFICIENCY]
#Edited Variable 2: Potential Change EIP 
big_Dt_CSsubset_N6M7[, nn_potIE := n_ENVIRONMENT_IMPACT_POTENTIAL - n_ENVIRONMENT_IMPACT_CURRENT]

#Edited Variable 3: Combine all terraced housing
#Old levels: "unknown","End-Terrace","Detached","Mid-Terrace", "Semi-Detached"
big_Dt_CSsubset_N6M7[, nn_builtForm := n_builtForm]
levels(big_Dt_CSsubset_N6M7$nn_builtForm)[levels(big_Dt_CSsubset_N6M7$nn_builtForm)=='End-Terrace'] <- 'Terrace'
levels(big_Dt_CSsubset_N6M7$nn_builtForm)[levels(big_Dt_CSsubset_N6M7$nn_builtForm)=='Mid-Terrace'] <- 'Terrace'
```





```{r CSSubset}
#bonus task: add CO2_EMISSIONS_CURRENT from raw
big_Dt_CSsubset_N6M7
#N = 16 744 771, ncol = 56
names(big_Dt_CSsubset_N6M7)
```
```{r naChecks}
if(F){
#there are no missing values 
nas <- which(is.na(big_Dt_CSsubset_N16M7$CURRENT_ENERGY_EFFICIENCY))
nas <- which(is.na(big_Dt_CSsubset_N16M7$POTENTIAL_ENERGY_EFFICIENCY))
nas <- which(is.na(big_Dt_CSsubset_N16M7$n_potEE))

nas <- which(is.na(big_Dt_CSsubset_N16M7$ENVIRONMENT_IMPACT_CURRENT))
nas <- which(is.na(big_Dt_CSsubset_N16M7$ENVIRONMENT_IMPACT_POTENTIAL))
nas <- which(is.na(big_Dt_CSsubset_N16M7$n_potEIC)) 

#contains nas!
nas <- which(is.na(big_Dt_CSsubset_N16M7$TOTAL_FLOOR_AREA)) 
}
```


```{r}
#anki order vs setorder # https://stackoverflow.com/questions/13685295/sort-a-data-table-fast-by-ascending-descending-order

#big_Dt_CSsubset_N6M7 <- big_Dt_CSsubset_N6M7[order(n_UPRN, -rank(INSPECTION_DATE) ),]
setorder(big_Dt_CSsubset_N6M7, n_UPRN, -INSPECTION_DATE) 


head(big_Dt_CSsubset_N6M7[duplicated(n_UPRN)])
sum(duplicated(big_Dt_CSsubset_N6M7$n_UPRN))#909 529

dupsrm <- big_Dt_CSsubset_N6M7[!duplicated(big_Dt_CSsubset_N6M7$n_UPRN)]

```


```{r NS_dt_censorship}
#Unexplained high values
NS_dt <- dupsrm[ n_CURRENT_ENERGY_EFFICIENCY < 101,] # drops = 3 094 
NS_dt <- NS_dt[ n_ENVIRONMENT_IMPACT_POTENTIAL < 101,] # drops a further = 92 699

NS_dt[, n_CURRENT_ENERGY_EFFICIENCY := NULL]
NS_dt[, n_ENVIRONMENT_IMPACT_POTENTIAL := NULL]

maxthreshold <- round(quantile(dupsrm$TOTAL_FLOOR_AREA, 0.99, na.rm = T),0) 
minthreshold <- round(quantile(dupsrm$TOTAL_FLOOR_AREA, 0.01, na.rm = T),0) 

NS_dt <- NS_dt[ minthreshold < NS_dt$TOTAL_FLOOR_AREA,] # drops a further ~ 167 731 
NS_dt <- NS_dt[ maxthreshold > NS_dt$TOTAL_FLOOR_AREA,] # drops a further ~ 166 758
NS_dt[, n_TOTAL_FLOOR_AREA := NULL]
NS_dt <- NS_dt[ !is.na(TOTAL_FLOOR_AREA),] # checks 

#cannot explain, so removed
NS_dt <- NS_dt[ n_construction_age_band != 'unknown',] # drops 208 708

sample <- lengths(NS_dt )[1] # 16 440 270 
sample

#save( NS_dt , file = "../Outputs/WIP_crossSectional/NS_subset_N16m111443.RData")



#NS_dt[ order( )]
#had dups issue
#save( NS_dt , file = "../Outputs/WIP_crossSectional/NS_subset_N16m440270.RData")
```





























#####################################################
#####################################################


```{r checker_big_crossSect_EPCs_cleaned_N16m984358}

#big_SC_dt<- loadRData( paste0("../Data/RData_crossSectional/big_crossSect_EPCs_cleaned_N16m984358.RData") )
print(paste('Number of entries without an UPRN', 
            format(sum(is.na(big_SC_dt$n_UPRN)), big.mark = ' ')  ))

print(paste('Percent of entries without an UPRN', 
            format(round(sum(is.na(big_SC_dt$n_UPRN))/lengths(big_SC_dt)[1] *100), big.mark = ' '),'%'  ))




#the ONS UPRNs will have some but not all UPRNs in the SC data
#this means I will have some but not all geography info for entries in the SC data
found = lengths(additional_ONSUD_dt[!is.na(additional_ONSUD_dt$n_UPRN),])[1] 
print(paste('Number of UPRNs found in ONSDUF', 
            format( found , big.mark = ' ')  ))

non_na_n_UPRNs <-  lengths(big_SC_dt[!is.na(big_SC_dt$n_UPRN),])[1]
print(paste('Percent UPRN found in ONSUD', 
            format(round( found / non_na_n_UPRNs, 3)*100, 
            big.mark = ' '),'%'  ))
```



```{r check_that_no_LMK-Key_is_Duped}
setwd("C:\\Users\\bonni\\Dropbox\\_PhD\\Application Documents\\CASA RA\\RA OS NARRATE CASA\\Code")
LMK_dups <- setnames(data.table(matrix(nrow = 0, ncol = 2) ), c('LAD','duped_LMK_KEY'))


LA= "domestic-E07000064-Rother"

 for (LA in folders) {
  print_counter = print_counter+1
  if(print_counter %% 20 == 0){print(LA)} 
  
  suppressWarnings(certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
                                         select =  "LMK_KEY", 
                                         colClasses="character"))
  
 if( sum(duplicated(certificates$LMK_KEY)) > 0){
   print(paste( '!!!! Duped LMK!!!!!') 
   }else(print('*'))
  
}
```


```{r}
CS <- data.table(A = letters[1:10],key = "A")

adt2 <- data.table(A = letters[5:12], Y = 1:8, key = "A")
adt3 <- data.table(A = letters[2:3], Y = 1:2, key = "A")


a <- adt2[CS, on = "A"]#first join
a <- adt3[a, on = "A"]

setnames(a, c('A','join', 'merge'))
a[ , issue_LMK_Key_duped := ifelse( !is.na(join) & !is.na(merge), T , F)]
a[ , join := ifelse( is.na(join), merge, join)][, merge:= NULL]


a <- merge(adt1, adt2, all.x = T)
a <- merge(a, adt3, all.x = T)







set.seed(1)
X <- data.table( a=letters, b=letters, c=letters, g=sample(c(1:5,7),length(letters),replace=TRUE), key="g" )
Y <- data.table( z=runif(6), g=1:6, key="g" )
```






```{r places_with_no_UPRNs}
no_UPRN <- list() 

for (LA in region_LUT$folder_name) {
#read subset only for speed:
  readcols <- c("LMK_KEY","INSPECTION_DATE","UPRN","ADDRESS","POSTCODE",
                "UPRN_SOURCE","CURRENT_ENERGY_RATING","CURRENT_ENERGY_EFFICIENCY",
                "LOCAL_AUTHORITY","LOCAL_AUTHORITY_LABEL")
  
  #read all as char, then parse for error catching
  my_colClasses <- cbind.data.frame(readcols,  c( rep('character',length(readcols)) )  )
  #read as data.tables
  certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
                       select =  readcols, 
                       colClasses=my_colClasses)
  setkey(certificates, LMK_KEY)

      col_ubdc_LUT <- ubdc_LUT[certificates$LMK_KEY, 'ubdc_uprn']
    certificates[,ubdc_UPRN := col_ubdc_LUT]
    
    ##combined str dups
    certificates[,str_concat := paste(ADDRESS, POSTCODE)]

    ###make col n_UPRN where this would UPRN, 
    certificates[ , n_UPRN := UPRN] 
    #or take ubdc_UPRN where its missing
    certificates[ n_UPRN == '',  n_UPRN := ubdc_UPRN]
    
    
    
    mising_UPRN <- is.na(certificates$UPRN)
    missing_n_UPRN <- is.na(certificates$n_UPRN)
    
    #places that could be found in the OS DataBase. 
    View(certificates[missing_n_UPRN])
    
    no_UPRN <- rbindlist(list(no_UPRN, certificates[missing_n_UPRN] ))
}  
```

```{r assign region to unknownLAD}
unknown_region_df<- loadRData( paste0("../Outputs/WIP_crossSectional/crossSectional_baseline_","Unknown",".RData") )
setkey(unknown_region_df, n_UPRN)

#tmp <-  unknown_region_df #head(unknown_region_df, 100)

for(ONSUD in EDA_cols$ONSUD){
  #for every ONS file, check if we can assign a region based on the UPRN data
  start.time <- Sys.time()
  if(is.na(ONSUD))break;  
  ONSUD_MAY_2020 <- fread(paste0("../Data/ONSUD_MAY_2020/Data/ONSUD_MAY_2020_",ONSUD,".csv"),
                          colClasses = c("uprn" = "character"))
  setkey(ONSUD_MAY_2020, uprn)

  unknown_region_df$uprn <- unknown_region_df$n_UPRN
  unknown_region_df[ONSUD_MAY_2020, on = 'uprn', oa11cd := i.oa11cd]
  unknown_region_df[ONSUD_MAY_2020, on = 'uprn', lad19cd := i.lad19cd]
  unknown_region_df[ONSUD_MAY_2020, on = 'uprn', lsoa11cd := i.lsoa11cd]
  unknown_region_df[ONSUD_MAY_2020, on = 'uprn', rgn17cd := i.rgn17cd]
  #print(ONSUD)
}
 
  #merge additional raw data
  setkey(unknown_region_df,LMK_KEY)
  unknown_region_df <- additional_dt[unknown_region_df, on = 'LMK_KEY']

print(paste('loop time:', Sys.time() - start.time))# 15 mins

dt_for_assignmnet <- unknown_region_df[!is.na(lsoa11cd),]
#8 249 of 9 794 are assigned a LSOA, using UPRNs only 
```








## Checking for dups


```{r}
setcolorder(region_df, c("n_UPRN", setdiff(names(region_df), "n_UPRN")))
View( region_df[duplicated(region_df$n_UPRN)][order(n_UPRN)]  ) 
```

```{r}

big_P2B1_Dt <- data.table()

for (WIP in cross_data) {
  print(paste(WIP, Sys.time()))
  region_df <- loadRData(paste0("../Data/RData_crossSectional/crossSectional_",WIP,".RData") )
  #tmp <- tmp[,..cols]#make the df smaller here
  big_P2B1_Dt <- rbindlist(list(big_P2B1_Dt,region_df))

  
  total <- lengths(region_df)[1]
  dups <-   sum(duplicated(region_df$n_UPRN))
  
  print(paste(WIP,
              '- has total:', total,
              '| dups: ', dups, '- as per cent',
              round(dups/total * 100), '%' ))
}

```


```{r P3_CrossSectional_ONSUD}

big_ONSUD_Dt <- data.table()

for (WIP in cross_data) {
  print(paste(WIP, Sys.time()))
  region_df <- loadRData(paste0("../Data/RData_crossSectional/crossSectional_",WIP,".RData") )
  #tmp <- tmp[,..cols]#make the df smaller here
  big_ONSUD_Dt <- rbindlist(list(big_ONSUD_Dt,region_df))

  
  total <- lengths(region_df)[1]
  dups <-   sum(duplicated(region_df$n_UPRN))
  
  print(paste(WIP,
              '- has total:', total,
              '| dups: ', dups, '- as per cent',
              round(dups/total * 100), '%' ))
}
```

# P2B2_CS_MD template

```{r loop_template}
# #get folders
# cross_data <- list.files(path = "../Data/RData_crossSectional", pattern = NULL, all.files = FALSE,
#            full.names = FALSE, recursive = FALSE,
#            ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)
# 
# cross_data <- gsub(".RData","",as.character(cross_data))
# cross_data <- gsub("crossSectional_","",as.character(cross_data))


LAD_table <- data.table()
start.time <- Sys.time()

for (region in cross_data) {
  print(paste(region, Sys.time()))
  tmp <- loadRData(paste0("../Data/RData_crossSectional/crossSectional_",region,".RData") )
  
  
  for (LA in unique(tmp$LAD11NM)) {
    tmp_LA <- tmp # tmp[ LAD11NM == LA, c('a','b','c')]
    #t_LAD_row <- tmp_LA[,.N ,by = c('x','y','z')]
  }
}

print(paste('loop time:', Sys.time() - start.time))#empty loop runs about 10 mins

if(F){
  save(tmp, file = paste0("../Outputs/WIP_crossSectional/crossSectional_baseline_",region,".RData") )
  write.xlsx(LAD_table,
             file = "../Data/CrossSectional_Summary.xlsx", sheetName="SHEET", append=TRUE)
}

print(paste('save time:', Sys.time() - start.time))
```


```{r loop_data_query}
# #get folders
# cross_data <- list.files(path = "../Data/RData_crossSectional", pattern = NULL, all.files = FALSE,
#            full.names = FALSE, recursive = FALSE,
#            ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)
# 
# cross_data <- gsub(".RData","",as.character(cross_data))
# cross_data <- gsub("crossSectional_","",as.character(cross_data))
LAD_table <- data.table()
start.time <- Sys.time()

for (region in cross_data) {
  print(paste(region, Sys.time()))
  tmp <- loadRData(paste0("../Data/RData_crossSectional/crossSectional_",region,".RData") )
  
  
  for (LA in unique(tmp$LAD11NM)) {
    tmp_LA <- tmp # tmp[ LAD11NM == LA, c('a','b','c')]
    #t_LAD_row <- tmp_LA[,.N ,by = c('x','y','z')]
  }
}

print(paste('loop time:', Sys.time() - start.time))#empty loop runs about 10 mins

if(F){
  save(tmp, file = paste0("../Outputs/WIP_crossSectional/crossSectional_baseline_",region,".RData") )
  write.xlsx(LAD_table,
             file = "../Data/CrossSectional_Summary.xlsx", sheetName="SHEET", append=TRUE)
}

print(paste('save time:', Sys.time() - start.time))
```



#possibly delete


```{r checking_where_dups_come}

CS_big_Dt <- data.table()
for (region in cross_data) {
  #region = cross_data[4] #testing
  print(paste(region, Sys.time()))
  
  tmp <- loadRData(paste0("../Data/RData_crossSectional/crossSectional_",region,".RData") )
  CS_big_Dt <- rbindlist(list(CS_big_Dt,tmp))
}

sum(duplicated(CS_big_Dt$n_UPRN)) #  1 564 548


ONSUD_big_Dt <- data.table()
for (WIP in EDA_cols$geography_name) {
 if(WIP == "Unknown") break; 
 region_df <- loadRData(paste0("../Outputs/WIP_crossSectional/ONSUD_crossSectional_baseline_",WIP,".RData") ) 
 region_df$CURRENT_ENERGY_EFFICIENCY <- as.numeric(region_df$CURRENT_ENERGY_EFFICIENCY)
 region_df$regionName
 ONSUD_big_Dt <- rbindlist(list(ONSUD_big_Dt,region_df))
}

sum(duplicated(ONSUD_big_Dt$n_UPRN)) #  94 3614
```


```{r debugging}
#P4_CrossSectional_EDA_Agebands_Builtform_Propertytype.Rmd
big_Dt_CSsubset_N6M7 <- loadRData("../Outputs/WIP_crossSectional/ONSUD_crossSectional_subset_N16744771.RData") #see
sum(duplicated(big_Dt_CSsubset_N6M7$n_UPRN)) # 909 529

big_Dt_CSsubset_N6M7[ test:= concatenate()]
```






```{r check}
#327 LAD, 10 + 1 regions
check <- data.frame()

loadRData <- function(fileName){
    #loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}

long_data <- list.files(path = "../Data/RData_longitudinal", pattern = NULL, all.files = FALSE,
           full.names = FALSE, recursive = FALSE,
           ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)

for (region in long_data) {
    tmp_region_dt <- loadRData(paste0("../Data/RData_longitudinal/",region) )
    
   for(LA in unique(tmp_region_dt[, LAD11NM]) ){ 
     check <- rbind(check, cbind(region, LA))
     
   }
}
```

```{r check1 loop thourgh }
longitudinalEPCs_long <- data.frame()
print_counter = 0

#using this instead of directory folders, to sort by region
regional_LUT <- fread("../Data/folders_geography_LUT.csv")
folders_sorted_by_regional_LUT <- regional_LUT[order(RGN11NM)]$Folder

#replaces the if statement
previous_region <- regional_LUT[order(RGN11NM)]$RGN11NM[1]
  

  
  
start.time <- Sys.time()
for (LA in folders_sorted_by_regional_LUT) {

  
  #print(LA)
  folder <- LA
  regionID <- which(regional_LUT$Folder == LA)
  current_region <- regional_LUT[regionID]$RGN11NM
  
      if(current_region == previous_region){
      print('in: current_region == previous_region')
    }else if(current_region != previous_region){
      longitudinalEPCs_long <- rbind(longitudinalEPCs_long, c('-------', '-------', '-------' ))
      previous_region<- current_region  
    }
  
  
  #print_counter = print_counter+1
  #if(print_counter %% 20 == 0){print(LA)} 
 
  row <- c( previous_region, current_region, LA )
  longitudinalEPCs_long <- rbind(longitudinalEPCs_long, row, stringsAsFactors = FALSE)
  names(longitudinalEPCs_long) <- c('previous_region','current_region','LAD')    

  }
  
print(paste('loop time:', Sys.time() - start.time))
```



```{r loop through raw EPC}
 #print_counter = print_counter+1
  #if(print_counter %% 20 == 0){print(LA)} 
  if(F){
    certificates <- fread(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"),
                        colClasses = 'character',
                        select = 'LOCAL_AUTHORITY_LABEL')
  

    
    ## Create a list of places by region:
    ####NOTE: assumes the regions will be seen in order
    if(LA == folders_sorted_by_regional_LUT[1]){
      previous_region <- r_region
      print('in: folders_sorted_by_regional_LUT[1]')
    }
    
    if(r_region == previous_region){
    longitudinalEPCs_long <- rbind(longitudinalEPCs_long, row)
    print('in: r_region == previous_region')
      
    }else if(r_region != previous_region){
      
      print(previous_region)
      previous_region<- regional_LUT[LA]$RGN11NM  
      
      longitudinalEPCs_long <- rbind(longitudinalEPCs_long, c('-------', '-------' ))
      longitudinalEPCs_long <- rbind(longitudinalEPCs_long, row)
     print('in: r_region != previous_region') 
     
    }
   #------------------------------------------------------------------------------------------------------------------------------
}
```



