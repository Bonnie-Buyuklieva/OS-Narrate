---
title: "Duplicate (strings) EPCs in V10"
author: "Boyana Buyuklieva"
date: "May 20, 2022"
output: html_document
---

#This version is has linear time complexity. 

```{r setup, include=FALSE, echo = T}
knitr::opts_chunk$set(echo = TRUE)
library(readr)

start.time <- Sys.time()
ubdc_link <- read_csv("../Data/ubdc_link.csv", 
    col_types = cols(record = col_character(), 
        record1 = col_character()))
print(paste('load time:', Sys.time() - start.time)) #"load time: 17.206854279836"



start.time <- Sys.time()
ubdc_link <- ubdc_link[order(ubdc_link$ubdc_uprn),]  
print(paste('sort time:', Sys.time() - start.time)) #"sort time: 16.833909034729"
```



```{r checks}
subsetCols <- c("LMK_KEY","INSPECTION_DATE","LODGEMENT_DATE",
            "CURRENT_ENERGY_RATING",
            "CURRENT_ENERGY_EFFICIENCY",
            "ADDRESS", "POSTCODE",
            "UPRN","UPRN SOURCE","LOCAL_AUTHORITY", "LOCAL_AUTHORITY_LABEL","POSTTOWN","CONSTITUENCY_LABEL")
```


# Duplicate Defintion Testing

```{r path}
#get folders
folders <- list.files(path = "../Data/all-domestic-certificates", pattern = NULL, all.files = FALSE,
           full.names = FALSE, recursive = FALSE,
           ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)

folders <- folders[-342] #remove the .txt
```


```{r loop}
str_dups <- data.frame()
uprn_dups <- data.frame()

tenure_LUT <- list ()


for (f in folders) {
  print(f)
  LA <- f
  certificates <- read_csv(paste0("../Data/all-domestic-certificates/",LA,"/certificates.csv"), 
    col_types = cols(COUNTY = col_character(), MAIN_HEATING_CONTROLS = col_character(),
        INSPECTION_DATE = col_date(format = "%Y-%m-%d"), 
        LMK_KEY = col_character(), LODGEMENT_DATE = col_date(format = "%Y-%m-%d"), 
        LODGEMENT_DATETIME = col_character()))
  #LODGEMENT_DATETIME = col_character() because it sometimes includes H:M:S
  
  certificates <- certificates[,subsetCols]
  
  ###Dups df #######################################
  
  ##Baseline: by string match
  certificates$combined <- paste0(certificates$ADDRESS, certificates$POSTCODE) #measure of repeat entry here
  tmpdups <- certificates[duplicated(certificates$combined) | duplicated(certificates$combined, fromLast = TRUE),]
  tmpdups$folder <- LA #folder info
  tmpdups <- tmpdups[order(tmpdups$combined, tmpdups$INSPECTION_DATE),]
  str_dups <- rbind(str_dups,tmpdups)
  
  ##Based on UPRNs
  #Count empty UPRNs
  tmpdups1 <- certificates[duplicated(certificates$UPRN) | duplicated(certificates$UPRN, fromLast = TRUE),]
  naUPRN <- sum(is.na(certificates$UPRN))
  
  
  ##Manual Based on Bin's V9:
  start.time <- Sys.time()
  certificates <- certificates[order(certificates$LMK_KEY),] #order certificates as the LUT
  tmpdups3_1 <- certificates[duplicated(certificates$UPRN) | duplicated(certificates$UPRN, fromLast = TRUE),]
  print(paste('time with unlist:', Sys.time() - start.time)) # "time with unlist: 12.073844909668"
  
  
  start.time <- Sys.time()
  certificates <- certificates[order(certificates$LMK_KEY),] #order certificates as the LUT
  certificates$udbc_UPRN <- ubdc_link$ubdc_uprn[match(unlist(certificates$LMK_KEY), ubdc_link$lmk_key)]
  tmpdups3_2 <- certificates[duplicated(certificates$UPRN) | duplicated(certificates$UPRN, fromLast = TRUE),]
  print(paste('time without unlist:', Sys.time() - start.time)) #"time without unlist: 5.79278898239136"
  
  
  
  # % one-off entries by folder.
  folders_meta[folders_meta$name == LA,]$totalEntries <- length(certificates$LMK_KEY) #denominator
  
  folders_meta[folders_meta$name == LA,]$PerCentOneOffEntries <- 1 - length(tmpdups$LMK_KEY)/length(certificates$LMK_KEY) 
  
}

#write.csv(folders_meta, '../Outputs/folder_meta.csv')

unique <- as.data.frame(unlist(tenure_LUT))
unique <- unique(unique$`unlist(tenure_LUT)`)
#write.csv(unique(unlist(unique )), '../Outputs/WIP_tenure_LUT.csv')
```









# Feature Engineering Set-Up

```{r heavyload, cache=TRUE}
start.time <- Sys.time()


#loads str_dups [7 847 301]
load(file = './MetaData&StringDups.RData')

#Df of all rows that repeat
tmp <- str_dups[,subsetCols ]
rm(str_dups)

##memory.size()
gc()#collect garbage 


#order by similarity & date
dupcol <- 'combined'
date <- 'INSPECTION_DATE'

tmp <- tmp[order(tmp[,dupcol],tmp[,date]),]
#create a faster key, based on the order
tmp$n_IDx <- seq(1,length(tmp$LMK_KEY),1)


print(paste('time to load:', Sys.time() - start.time))#9 mins
```

```{r define_engineered-features, cache=TRUE}
start.time <- Sys.time()


#flag first entries   
tmp$n_firstEntry <- F
firstEntry <-which(!duplicated(tmp$combined)) #3539058
tmp$n_firstEntry[firstEntry] <- T 
rm(firstEntry)

#set up the time column, relative to Inspection Date
tmp$n_deltaDays <-  0

#Delta(ER)
#might cause problems without trimming white spaces and caps
tmp$n_dER <- as.numeric(factor(tmp$CURRENT_ENERGY_RATING, 
                       ordered = T, levels = c('A','B','C','D','E','F','G')))
tmp$n_dEE <- tmp$CURRENT_ENERGY_EFFICIENCY


print(paste('runtime:', Sys.time() - start.time))#2 mins
```

```{r checks}
checks <- c("n_IDx","n_firstEntry","combined",
            "INSPECTION_DATE","n_deltaDays",
            "CURRENT_ENERGY_RATING","n_dER",
            "CURRENT_ENERGY_EFFICIENCY","n_dEE",
            "LMK_KEY","LOCAL_AUTHORITY")
```




#Simplified Version of Deltas

```{r solved_faster}

testingN <- length(tmp$combined)
# testingN <- 50000

start.time <- Sys.time()
tester <- head(tmp,testingN)


#vector giving  start of the repeats / group 
rangeStarts <- numeric(testingN)
for (row in tester$n_IDx) {
  
  if (tester$n_firstEntry[row] == T) {
    groupStart <- row
  }
  
  rangeStarts[row] <- groupStart
} 
print(paste('loop runtime:', Sys.time() - start.time)) # (.2 sec / 5k)  (20s / 8M)



start.time <- Sys.time()
tester$n_dER <- tester$n_dER[rangeStarts] - tester$n_dER # factor as numbers
tester$n_dEE <- tester$n_dEE - tester$n_dEE[rangeStarts]
tester$n_deltaDays <- as.numeric(difftime(tester$INSPECTION_DATE, tester$INSPECTION_DATE[rangeStarts], units = c("days"))) 
print(paste('operation runtime:', Sys.time() - start.time)) # (0.01 sec / 5k) (.5 / 8M)


print(paste('runtime:', Sys.time() - start.time)) # (approx 60s / 8 m)

#View(tester[,checks])

```



